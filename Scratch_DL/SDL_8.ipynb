{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 8 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손글씨 숫자를 인식하는 심층 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Conv-ReLU-Conv-ReLU-Pool) $\\rightarrow$ (Conv-ReLU-Conv-ReLU-Pool) $\\rightarrow$ (Conv-ReLU-Conv-ReLU-Pool) $\\rightarrow$ (Affine-ReLU-Dropout) $\\rightarrow$ (Affine-Dropout-Softmax)\n",
    "- VGG 신경망 참고\n",
    "- 합성곱 계층은 모두 3X3 크기의 작은 필터로 층이 깊어지면서 채널 수가 늘어남\n",
    "- 앞 계층부터 순서대로 16, 16, 32, 32, 64, 64\n",
    "- 풀링 게층을 추가하여 중간 데이터의 공간 크기를 점차 줄임\n",
    "- 완전연결 계층에서는 드롭아웃 계층을 사용\n",
    "- 가중치 초깃값으로 He 초깃값을 사용\n",
    "- 가중치 매개변수 갱신에는 Adam 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 구현 소스 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습시키는 데 매우 오랜 시간\n",
    "- deep_convnet.py\n",
    "- train_deepnet.py\n",
    "- 학습된 가중치 매개변수 파일\n",
    "    - deep_conv_net_params.pkl (deep_convnet.py로 읽어들일 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <What is the class of this image?> 웹사이트, 기법들의 정확도 순위 정리\n",
    "- 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌\n",
    "- 정확도 향상: 이미지의 회전, 이동, 변형, 삭제 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 깊게 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이론적인 근거는 아직 많이 부족하지만 다음과 같은 설명\n",
    "- 신경망의 매개변수 수가 줄어듬, 작은 필터를 겹쳐 매개변수 수를 줄이고 수용 영역 소화\n",
    "- 5X5 합성곱 연산 1회는(매개변수 25) 3X3 합성곱 연산 2회로(매개변수 18) 대체 가능\n",
    "- 학습 데이터의 양을 줄이고, 따라서 속도도 개선\n",
    "- 층이 깊어지면서 복잡한 특징을 이해하게 됨\n",
    "- 신경망을 깊게 하면 학습해야 할 문제를 계층적으로 분해할 수 있음(풀기 쉽도록)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 딥러닝의 초기 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 인식 기술을 겨루는 ILSVRC의 2012년 대회에서 AlexNet이 압도적 우승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 이미지넷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100만 장이 넘는 이미지를 담고 있는 데이터셋\n",
    "- ILSVRC에서 이를 이용한 대회, 시험 항목 중 하나는 분류\n",
    "- ResNet이 2015년 오류율 3.5%로 1위, 인간의 인식 수준을 넘어섬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN\n",
    "- 층의 깊이에 따라서 VGG16과 VGG19로 구분하기도 함\n",
    "- 3X3의 작은 필터를 사용한 합성곱 계층을 연속으로 거침\n",
    "- 성능도 2014년 2위를 할 정도로 좋지만 구성이 간단하여 응용이 편함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세로 방향 깊이뿐 아니라 가로 방향도 깊음\n",
    "- 가로 방향에 폭이 있는 인셉션 구조\n",
    "- 인셉션 구조는 크기가 다른 필터와 풀링을 여러 개 적용하여 그 결과를 결합\n",
    "- 1X1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용\n",
    "- 그것은 매개변수 제거와 고속 처리에 기여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마이크로소프트 팀이 개발\n",
    "- 층이 지나치게 깊으면 학습이 잘 되지 않음\n",
    "- 스킵 연결을 도입\n",
    "- 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조\n",
    "- 단축 경로가 없었다면 두 합성곱 계층의 출력이 F(x)이나 스킵 연결로 F(x) + x가 됨\n",
    "- 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문에 학습이 효율적으로 가능\n",
    "- 층을 깊게 할수록 기울기가 작아지는 소실 문제를 줄여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지넷이 제공하는 데이터셋으로 학습한 가중치 값들은 실제로도 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전이 학습이라고 해서, 학습된 가중치를 다른 신경망에 복사한 다음 그 상태로 재학습\n",
    "- 미리 학습된 가중치를 초깃값으로 설정\n",
    "- 보유한 데이터셋이 적을 때 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 더 빠르게(딥러닝 고속화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝의 프레임워크 대부분은 GPU를 활용한 대량 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 풀어야 할 숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떻게 속도를 빠르게 할 것인가?\n",
    "- AlexNet의 forward 처리에서 각 층이 소비하는 시간\n",
    "    - 합성곱 계층의 처리 시간은 GPU 전체 95%, CPU 전체 89%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 GPU를 활용한 고속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU 컴퓨팅\n",
    "- 최근에는 GPU를 범용 수치 연산에도 이용 (병렬 수치 연산을 고속으로 처리 가능)\n",
    "- 실제로 CPU만 쓸 때보다 몇 배는 빠르게 연산 가능\n",
    "- GPU는 주로 엔비디아와 AMD, 보통은 CUDA라는 엔비디아의 GPU 컴퓨팅용 통합 개발 환경\n",
    "- cuDNN은 CUDA 위에서 동작하는 라이브러리\n",
    "- 합성곱 계층에서 행하는 연산은 im2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 분산 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU로 딥러닝 연산 빠르게 할 수 있으나, 심층 신경망에는 며칠에서 몇 주가 걸리기도 함\n",
    "- 따라서 분산 학습이 중요\n",
    "- 구글의 텐서플로, 마이크로소프트의 CNTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 연산 정밀도와 비트 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 메모리 용량과 버스 대역폭 등이 딥러닝 고속화에 병목이 될 수 있음\n",
    "- 컴퓨터는 주로 64비트나 32비트 부동소수점 수를 사용해 실수 표현\n",
    "- 계산 오차는 줄어드나 계산에 드는 비용이나 메모리 사용량, 버스 대역폭 부담\n",
    "- 딥러닝은 높은 수치의 정밀도를 요구하지 않음\n",
    "- 흐르는 데이터를 퇴화시켜도 출력에 주는 영향력이 적음, 강건함, 견고성\n",
    "- 16비트 반정밀도를 사용해도 학습에 문제가 없음\n",
    "- 엔비디아의 GPU 파스칼 아키텍처는 이 포맷을 지원\n",
    "- half_float_network.py 참고\n",
    "- 딥러닝의 비트 수를 줄이는 연구도 진행\n",
    "- 가중치와 중간 데이터를 1비트로 표현하는 [Binarized Neural Networks] 방법도 등장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 딥러닝의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사물 인신뿐 아니라 온갖 문제에 적용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 사물 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 속에 담긴 사물의 위치와 종류를 알아내는 기술\n",
    "- 사물 인식보다 어려운 문제\n",
    "- 한 이미지에 여러 사물이 존재할 수도 있기 때문\n",
    "- CNN 기반의 R-CNN이 유명 (Selective Search 기법 사용)\n",
    "    - 입력 이미지\n",
    "    - 후보 영역 추출\n",
    "    - CNN 특징 계산\n",
    "    - 영역 분류\n",
    "- 이미지를 사각형으로 변형하거나 분류할 때 서포트 벡터 머신을 이용하는 등 다소 복잡\n",
    "- 후보 영역 추출과 CNN 특징 계산으로 구성\n",
    "- Faster R-CNN에서는 모든 일이 하나의 CNN에서 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지를 픽셀 수준에서 분류하는 문제\n",
    "- 픽셀 단위로 객체마다 채색된 지도 데이터를 사용해 학습\n",
    "- 추론할 때 입력 이미지의 모든 픽셀을 분류\n",
    "- 가장 단순한 방법은 모든 픽셀 각각을 추론\n",
    "- 하지만 오래 걸리기 때문에 FCN 고안 (단 한번의 forward 처리로 모든 픽셀 클래스 분류)\n",
    "- Fully Convolutional Network: 합성곱 계층만으로 구성된 네트워크\n",
    "- 공간 볼륨을 유지한 채 마지막 출력까지 처리\n",
    "- 마지막 공간 확대 처리는 이중 선형 보간에 의한 선형 확대\n",
    "- 역합성곱 연산으로 구현\n",
    "- 입력 크기가 32X10X10인 데이터에 대한 완전연결 계층은 필터 크기가 32X10X10인 합성곱 계층으로 대체할 수 있음\n",
    "- 완전연결 계층의 출력 노드가 100개라면 합성곱 계층에서는 기존의 필터를 100개 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 사진 캡션 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컴퓨터 비전과 자연어를 융합한 연구\n",
    "- 사진을 주면 사진에 대한 설명을 자동으로 생성\n",
    "- NIC 모델이 대표적\n",
    "- 심층 CNN과 RNN으로 구성\n",
    "- CNN으로 추출한 사진의 특징을 RNN에 넘김\n",
    "- 여러 종류의 정보를 조합하고 처리하는것을 멀티모달 처리라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 딥러닝의 미래"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 이미지 스타일(화풍) 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 이미지를 입력해서 새로운 그림을 그리는 연구\n",
    "- '콘텐츠 이미지', '스타일 이미지'를 조합해 새로운 그림\n",
    "- 스타일 행렬이라는 개념 도입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아무런 입력 이미지 없이도 새로운 이미지를 그려내는 연구\n",
    "- 학습 때는 대량의 이미지를 사용하여 학습하지만, 학습이 끝난 후에는 새로운 그림 가능\n",
    "- DCGAN 기법\n",
    "- 생성자와 식별자로 불리는 2개의 신경망 이용\n",
    "- 생성자가 진짜와 똑같은 이미지를 생성하고, 더 정교한 가짜 이미지 생성 기술 학습\n",
    "- 식별자가 그것이 진짜인지 판정, 더 정확하게 간파할 수 있도록 성장\n",
    "- GAN(Generative Adversarial Network)\n",
    "- 비지도 학습(자율 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3 자율 주행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최근 화두, 다양한 기술을 모아 구현\n",
    "- SegNet이라는 CNN 기반 신경망은 주변 환경을 정확하게 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4 Deep Q-Network(강화학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가르침에 의존하는 지도 학습과는 다른 분야\n",
    "- 에이전트라는 것이 환경에 맞게 행동을 선택하고 행동에 의해서 환경이 변함\n",
    "- 환경이 변화하면 에이전트는 보상을 얻음\n",
    "- 더 나은 보상을 받는 쪽으로 에이전트의 행동 지침을 바로잡는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Q-Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q학습이라는 강화학습 알고리즘을 기초로 함\n",
    "- 최적 행동 가치 함수로 최적인 행동을 정함\n",
    "- 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는것이 DQN\n",
    "- 비디오 게임을 자율 학습시켜 사람을 뛰어넘는 수준의 조작을 실현한 사례 보고\n",
    "- 각 동작의 가치를 출력\n",
    "- 게임마다 설정을 바꿀 필요없이 단순히 DQN에 게임 영상을 보여주기만 하면\n",
    "- 구성을 변경하지 않고도 많은 게임을 학습할 수 있음\n",
    "- 응용 가능성 무궁무진함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 정리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
